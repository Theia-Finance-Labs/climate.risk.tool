{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4d86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] workspace/GIRI_raw/flood_pc_500_glob.tif already exists.\n",
      "[SKIP] workspace/GIRI_raw/flood_pc_200_glob.tif already exists.\n",
      "[SKIP] workspace/GIRI_raw/flood_pc_100_glob.tif already exists.\n",
      "[SKIP] workspace/GIRI_raw/flood_pc_50_glob.tif already exists.\n",
      "[SKIP] workspace/GIRI_raw/flood_pc_25_glob.tif already exists.\n",
      "[SKIP] workspace/GIRI_raw/flood_pc_5_glob.tif already exists.\n",
      "[SKIP] workspace/GIRI_raw/flood_pc_2_glob.tif already exists.\n",
      "[SKIP] workspace/GIRI_raw/flood_rcp85_500_glob.tif already exists.\n",
      "[SKIP] workspace/GIRI_raw/flood_rcp85_200_glob.tif already exists.\n",
      "[SKIP] workspace/GIRI_raw/flood_rcp85_100_glob.tif already exists.\n",
      "[SKIP] workspace/GIRI_raw/flood_rcp85_50_glob.tif already exists.\n",
      "[SKIP] workspace/GIRI_raw/flood_rcp85_25_glob.tif already exists.\n",
      "[SKIP] workspace/GIRI_raw/flood_rcp85_5_glob.tif already exists.\n",
      "[INFO] Downloading workspace/GIRI_raw/flood_rcp85_2_glob.tif ...\n",
      "[OK] Saved workspace/GIRI_raw/flood_rcp85_2_glob.tif\n",
      "[INFO] Downloading workspace/GIRI_raw/flood_rcp26_500_glob.tif ...\n",
      "[OK] Saved workspace/GIRI_raw/flood_rcp26_500_glob.tif\n",
      "[SKIP] workspace/GIRI_raw/flood_rcp26_200_glob.tif already exists.\n",
      "[INFO] Downloading workspace/GIRI_raw/flood_rcp26_100_glob.tif ...\n",
      "[OK] Saved workspace/GIRI_raw/flood_rcp26_100_glob.tif\n",
      "[INFO] Downloading workspace/GIRI_raw/flood_rcp26_50_glob.tif ...\n",
      "[OK] Saved workspace/GIRI_raw/flood_rcp26_50_glob.tif\n",
      "[INFO] Downloading workspace/GIRI_raw/flood_rcp26_25_glob.tif ...\n",
      "[OK] Saved workspace/GIRI_raw/flood_rcp26_25_glob.tif\n",
      "[INFO] Downloading workspace/GIRI_raw/flood_rcp26_5_glob.tif ...\n",
      "[OK] Saved workspace/GIRI_raw/flood_rcp26_5_glob.tif\n",
      "[INFO] Downloading workspace/GIRI_raw/flood_rcp26_2_glob.tif ...\n",
      "[OK] Saved workspace/GIRI_raw/flood_rcp26_2_glob.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "scenarios = [\"pc\", \"rcp85\", \"rcp26\"]\n",
    "return_periods = [500, 200, 100, 50, 25, 5, 2]\n",
    "\n",
    "folderr = \"workspace/GIRI_raw/\"\n",
    "os.makedirs(folderr, exist_ok=True)\n",
    "\n",
    "for scenario in scenarios:\n",
    "    for rp in return_periods:\n",
    "        url = f\"https://hazards-data.unepgrid.ch/global_{scenario}_h{rp}glob.tif\"\n",
    "        filename = os.path.join(folderr, f\"flood_{scenario}_{rp}_glob.tif\")\n",
    "\n",
    "        if os.path.exists(filename):\n",
    "            print(f\"[SKIP] {filename} already exists.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"[INFO] Downloading {filename} ...\")\n",
    "        try:\n",
    "            r = requests.get(url, timeout=60)\n",
    "            if r.status_code == 200:\n",
    "                with open(filename, \"wb\") as f:\n",
    "                    f.write(r.content)\n",
    "                print(f\"[OK] Saved {filename}\")\n",
    "            else:\n",
    "                print(f\"[WARN] URL not found or unavailable: {url} (status {r.status_code})\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"[ERROR] Failed to download {url}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d1d95d",
   "metadata": {},
   "source": [
    "# setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f31aabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_pc_500_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_pc_200_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_pc_100_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_pc_50_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_pc_25_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_pc_5_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_pc_2_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp85_500_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp85_200_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp85_100_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp85_50_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp85_25_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp85_5_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp85_2_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp26_500_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp26_200_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp26_100_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp26_50_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp26_25_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp26_5_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp26_2_glob.tif\n",
      "[INFO] Combining arrays…\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray as rxr  # make sure: pip/conda install rioxarray\n",
    "\n",
    "folderr_brazil = \"../workspace/GIRI_raw/brazil\"\n",
    "\n",
    "# ---------------- config ----------------\n",
    "scenarios = [\"pc\", \"rcp85\", \"rcp26\"]\n",
    "return_periods = [500, 200, 100, 50, 25, 5, 2]\n",
    "\n",
    "\n",
    "out_nc  = \"../workspace/Flood/depth/ensemble_return_period.nc\"\n",
    "\n",
    "# map to human-readable names (as a coord)\n",
    "dict_scenarios = {\n",
    "    \"pc\": \"Present Climate\",\n",
    "    \"rcp85\": \"SSP5-8.5\",\n",
    "    \"rcp26\": \"SSP1-2.6\",\n",
    "}\n",
    "\n",
    "# crop extent (lon_min, lon_max, lat_max, lat_min)\n",
    "LON_MIN, LON_MAX = -75.0, -30.0\n",
    "LAT_MAX, LAT_MIN = 10.0, -35.0\n",
    "\n",
    "# chunk sizes for dask/xarray and NetCDF\n",
    "CHUNK_LAT, CHUNK_LON = 512, 512\n",
    "\n",
    "# ----------------------------------------\n",
    "list_da = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    for rp in return_periods:\n",
    "        fpath = os.path.join(folderr_brazil, f\"flood_{scenario}_{rp}_glob.tif\")\n",
    "        if not os.path.exists(fpath):\n",
    "            print(f\"[WARN] Missing: {fpath} (skipping)\")\n",
    "            continue\n",
    "\n",
    "        print(f\"[INFO] Opening: {fpath}\")\n",
    "        try:\n",
    "            da = rxr.open_rasterio(\n",
    "                fpath,\n",
    "                chunks={\"x\": CHUNK_LON, \"y\": CHUNK_LAT},\n",
    "                masked=True,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to open {fpath}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # squeeze band -> 2D (y,x)\n",
    "        if \"band\" in da.dims and da.sizes[\"band\"] == 1:\n",
    "            da = da.squeeze(\"band\", drop=True)\n",
    "\n",
    "        # ensure CRS; many global hazard tifs are EPSG:4326\n",
    "        if da.rio.crs is None:\n",
    "            da = da.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "        # crop (note: y usually descends; slice handles either order)\n",
    "        da = da.sel(x=slice(LON_MIN, LON_MAX), y=slice(LAT_MAX, LAT_MIN))\n",
    "\n",
    "        # rename dims/var\n",
    "        da = da.rename({\"x\": \"lon\", \"y\": \"lat\"})\n",
    "        da.name = \"flood_depth\"\n",
    "\n",
    "        # set dtype (float32 is compact and typical for depths)\n",
    "        da = da.astype(\"float32\")\n",
    "\n",
    "        # expand coords with scenario + return_period\n",
    "        da = da.expand_dims(\n",
    "            {\n",
    "                \"scenario\": [dict_scenarios.get(scenario, scenario)],\n",
    "                \"return_period\": [rp],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        list_da.append(da)\n",
    "\n",
    "# guard: anything loaded?\n",
    "if not list_da:\n",
    "    raise RuntimeError(\"No rasters were found/loaded. Check file names and folder.\")\n",
    "\n",
    "# combine by coords into one cube\n",
    "print(\"[INFO] Combining arrays…\")\n",
    "da_all = xr.combine_by_coords(list_da, combine_attrs=\"override\")\n",
    "\n",
    "# order dims\n",
    "da_all = da_all.transpose(\"scenario\", \"return_period\", \"lat\", \"lon\")\n",
    "\n",
    "# set some attrs\n",
    "da_all.attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"Flood depth\",\n",
    "        \"units\": \"m\",\n",
    "        \"source\": \"UNEP GRID hazards data\",\n",
    "        \"note\": \"Cropped to South America; scenarios labelled by human-readable names.\",\n",
    "    }\n",
    ")\n",
    "da_all[\"scenario\"].attrs[\"description\"] = \"Scenario label\"\n",
    "da_all[\"return_period\"].attrs[\"units\"] = \"years\"\n",
    "\n",
    "# rechunk uniformly for writing\n",
    "da_all = da_all.chunk({\"scenario\": 1, \"return_period\": 1, \"lat\": CHUNK_LAT, \"lon\": CHUNK_LON})\n",
    "\n",
    "# encode & save\n",
    "encoding = {\n",
    "    \"flood_depth\": {\n",
    "        \"zlib\": True,\n",
    "        \"complevel\": 4,\n",
    "        \"dtype\": \"float32\",\n",
    "        \"chunksizes\": (1, 1, CHUNK_LAT, CHUNK_LON),\n",
    "        \"_FillValue\": np.float32(np.nan),  # keep NaN for no-data\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f28682",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_nc  = \"../workspace/hazards/Flood/depth/ensemble_return_period.nc\"\n",
    "print(f\"[INFO] Writing NetCDF -> {out_nc}\")\n",
    "da_all.to_dataset(name=\"flood_depth\").to_netcdf(out_nc, encoding=encoding)\n",
    "print(\"[OK] Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
