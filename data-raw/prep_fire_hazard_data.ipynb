{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables - file paths\n",
    "tif_path = \"../workspace/FWI data/2024_Brazil_LandCover.tif\"\n",
    "nc_path = \"../workspace/hazards/Fire/FWI/ensemble_return_period_FWI_final.nc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from scipy import stats\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading TIF file metadata: ../workspace/FWI data/2024_Brazil_LandCover.tif\n",
      "File exists: True\n",
      "\n",
      "TIF file properties:\n",
      "  Width: 167551\n",
      "  Height: 144835\n",
      "  Number of bands: 1\n",
      "  CRS: EPSG:4326\n",
      "  Bounds: BoundingBox(left=-73.99593675196482, bottom=-33.75581376830244, right=-28.84184950111183, top=5.2764344843328335)\n",
      "  Transform: | 0.00, 0.00,-74.00|\n",
      "| 0.00,-0.00, 5.28|\n",
      "| 0.00, 0.00, 1.00|\n",
      "  Data type: uint8\n",
      "\n",
      "Spatial resolution:\n",
      "  Pixel size X: 0.00026949458523585647 degrees\n",
      "  Pixel size Y: 0.00026949458523585647 degrees\n"
     ]
    }
   ],
   "source": [
    "# Read TIF file metadata (without loading data into memory)\n",
    "print(f\"Reading TIF file metadata: {tif_path}\")\n",
    "print(f\"File exists: {os.path.exists(tif_path)}\")\n",
    "\n",
    "with rasterio.open(tif_path) as src:\n",
    "    print(f\"\\nTIF file properties:\")\n",
    "    print(f\"  Width: {src.width}\")\n",
    "    print(f\"  Height: {src.height}\")\n",
    "    print(f\"  Number of bands: {src.count}\")\n",
    "    print(f\"  CRS: {src.crs}\")\n",
    "    print(f\"  Bounds: {src.bounds}\")\n",
    "    print(f\"  Transform: {src.transform}\")\n",
    "    print(f\"  Data type: {src.dtypes[0]}\")\n",
    "    \n",
    "    # Calculate resolution from transform\n",
    "    transform = src.transform\n",
    "    pixel_size_x = abs(transform[0])  # Resolution in x direction\n",
    "    pixel_size_y = abs(transform[4])  # Resolution in y direction\n",
    "    print(f\"\\nSpatial resolution:\")\n",
    "    print(f\"  Pixel size X: {pixel_size_x} degrees\")\n",
    "    print(f\"  Pixel size Y: {pixel_size_y} degrees\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NetCDF file: ../workspace/hazards/Fire/FWI/ensemble_return_period_FWI_final.nc\n",
      "File exists: True\n",
      "\n",
      "============================================================\n",
      "NETCDF FILE STRUCTURE\n",
      "============================================================\n",
      "\n",
      "File format: NETCDF4\n",
      "File mode: NETCDF4\n",
      "\n",
      "============================================================\n",
      "DIMENSIONS:\n",
      "============================================================\n",
      "  GWL: 4 (unlimited: False)\n",
      "  lon: 168 (unlimited: False)\n",
      "  lat: 162 (unlimited: False)\n",
      "  return_period: 5 (unlimited: False)\n",
      "  ensemble: 4 (unlimited: False)\n",
      "\n",
      "============================================================\n",
      "VARIABLES:\n",
      "============================================================\n",
      "\n",
      "  Variable: GWL\n",
      "    Shape: (4,)\n",
      "    Dimensions: ('GWL',)\n",
      "    Data type: <class 'str'>\n",
      "    Attributes: ['long_name']\n",
      "      long_name: Global Warming Level\n",
      "\n",
      "  Variable: lon\n",
      "    Shape: (168,)\n",
      "    Dimensions: ('lon',)\n",
      "    Data type: float64\n",
      "    Attributes: ['_FillValue']\n",
      "      _FillValue: nan\n",
      "\n",
      "  Variable: lat\n",
      "    Shape: (162,)\n",
      "    Dimensions: ('lat',)\n",
      "    Data type: float64\n",
      "    Attributes: ['_FillValue']\n",
      "      _FillValue: nan\n",
      "\n",
      "  Variable: return_period\n",
      "    Shape: (5,)\n",
      "    Dimensions: ('return_period',)\n",
      "    Data type: int64\n",
      "    Attributes: []\n",
      "\n",
      "  Variable: ensemble\n",
      "    Shape: (4,)\n",
      "    Dimensions: ('ensemble',)\n",
      "    Data type: <class 'str'>\n",
      "    Attributes: []\n",
      "\n",
      "  Variable: FWI_mean\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "    Dimensions: ('ensemble', 'GWL', 'lat', 'lon', 'return_period')\n",
      "    Data type: float32\n",
      "    Attributes: ['_FillValue']\n",
      "      _FillValue: nan\n",
      "\n",
      "  Variable: FWI_max\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "    Dimensions: ('ensemble', 'GWL', 'lat', 'lon', 'return_period')\n",
      "    Data type: float32\n",
      "    Attributes: ['_FillValue']\n",
      "      _FillValue: nan\n",
      "\n",
      "  Variable: days_low\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "    Dimensions: ('ensemble', 'GWL', 'lat', 'lon', 'return_period')\n",
      "    Data type: float32\n",
      "    Attributes: ['_FillValue']\n",
      "      _FillValue: nan\n",
      "\n",
      "  Variable: days_moderate\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "    Dimensions: ('ensemble', 'GWL', 'lat', 'lon', 'return_period')\n",
      "    Data type: float32\n",
      "    Attributes: ['_FillValue']\n",
      "      _FillValue: nan\n",
      "\n",
      "  Variable: days_high\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "    Dimensions: ('ensemble', 'GWL', 'lat', 'lon', 'return_period')\n",
      "    Data type: float32\n",
      "    Attributes: ['_FillValue']\n",
      "      _FillValue: nan\n",
      "\n",
      "  Variable: days_very_high\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "    Dimensions: ('ensemble', 'GWL', 'lat', 'lon', 'return_period')\n",
      "    Data type: float32\n",
      "    Attributes: ['_FillValue']\n",
      "      _FillValue: nan\n",
      "\n",
      "  Variable: days_extreme\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "    Dimensions: ('ensemble', 'GWL', 'lat', 'lon', 'return_period')\n",
      "    Data type: float32\n",
      "    Attributes: ['_FillValue']\n",
      "      _FillValue: nan\n",
      "\n",
      "  Variable: days_danger_total\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "    Dimensions: ('ensemble', 'GWL', 'lat', 'lon', 'return_period')\n",
      "    Data type: float32\n",
      "    Attributes: ['_FillValue']\n",
      "      _FillValue: nan\n",
      "\n",
      "============================================================\n",
      "GLOBAL ATTRIBUTES:\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "COORDINATE VARIABLES (sample values):\n",
      "============================================================\n",
      "  GWL: ['present' '1.5' '2' '3']\n",
      "  lon: [-74.125, ..., -32.375] (size: 168)\n",
      "  lat: [-34.125, ..., 6.125] (size: 162)\n",
      "  return_period: [  5  10  25  50 100]\n",
      "  ensemble: ['mean' 'median' 'p10' 'p90']\n",
      "\n",
      "============================================================\n",
      "DATA VARIABLE SUMMARY:\n",
      "============================================================\n",
      "\n",
      "  FWI_mean:\n",
      "    Sample value at (0, 0, 0, 0, 0): --\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "\n",
      "  FWI_max:\n",
      "    Sample value at (0, 0, 0, 0, 0): --\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "\n",
      "  days_low:\n",
      "    Sample value at (0, 0, 0, 0, 0): --\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "\n",
      "  days_moderate:\n",
      "    Sample value at (0, 0, 0, 0, 0): --\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "\n",
      "  days_high:\n",
      "    Sample value at (0, 0, 0, 0, 0): --\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "\n",
      "  days_very_high:\n",
      "    Sample value at (0, 0, 0, 0, 0): --\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "\n",
      "  days_extreme:\n",
      "    Sample value at (0, 0, 0, 0, 0): --\n",
      "    Shape: (4, 4, 162, 168, 5)\n",
      "\n",
      "  days_danger_total:\n",
      "    Sample value at (0, 0, 0, 0, 0): --\n",
      "    Shape: (4, 4, 162, 168, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load and inspect the NetCDF file structure\n",
    "print(f\"Loading NetCDF file: {nc_path}\")\n",
    "print(f\"File exists: {os.path.exists(nc_path)}\")\n",
    "\n",
    "with nc.Dataset(nc_path, 'r') as ds:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"NETCDF FILE STRUCTURE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nFile format: {ds.file_format}\")\n",
    "    print(f\"File mode: {ds.data_model}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"DIMENSIONS:\")\n",
    "    print(\"=\"*60)\n",
    "    for dim_name, dim_obj in ds.dimensions.items():\n",
    "        print(f\"  {dim_name}: {dim_obj.size} (unlimited: {dim_obj.isunlimited()})\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"VARIABLES:\")\n",
    "    print(\"=\"*60)\n",
    "    for var_name, var_obj in ds.variables.items():\n",
    "        print(f\"\\n  Variable: {var_name}\")\n",
    "        print(f\"    Shape: {var_obj.shape}\")\n",
    "        print(f\"    Dimensions: {var_obj.dimensions}\")\n",
    "        print(f\"    Data type: {var_obj.dtype}\")\n",
    "        print(f\"    Attributes: {list(var_obj.ncattrs())}\")\n",
    "        if var_obj.ncattrs():\n",
    "            for attr in var_obj.ncattrs():\n",
    "                print(f\"      {attr}: {getattr(var_obj, attr)}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"GLOBAL ATTRIBUTES:\")\n",
    "    print(\"=\"*60)\n",
    "    for attr_name in ds.ncattrs():\n",
    "        print(f\"  {attr_name}: {getattr(ds, attr_name)}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"COORDINATE VARIABLES (sample values):\")\n",
    "    print(\"=\"*60)\n",
    "    # Try to identify coordinate variables\n",
    "    dim_names = list(ds.dimensions.keys())\n",
    "    for dim_name in dim_names:\n",
    "        if dim_name in ds.variables:\n",
    "            var_obj = ds.variables[dim_name]\n",
    "            if len(var_obj.shape) == 1 and var_obj.size <= 20:\n",
    "                values = var_obj[:]\n",
    "                print(f\"  {dim_name}: {values}\")\n",
    "            elif len(var_obj.shape) == 1:\n",
    "                values = var_obj[:]\n",
    "                print(f\"  {dim_name}: [{values[0]}, ..., {values[-1]}] (size: {len(values)})\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"DATA VARIABLE SUMMARY:\")\n",
    "    print(\"=\"*60)\n",
    "    # Find main data variable (exclude coordinate variables)\n",
    "    data_vars = [v for v in ds.variables.keys() if v not in dim_names]\n",
    "    for var_name in data_vars:\n",
    "        var_obj = ds.variables[var_name]\n",
    "        if len(var_obj.shape) >= 2:  # Likely a data variable\n",
    "            print(f\"\\n  {var_name}:\")\n",
    "            try:\n",
    "                # Try to get a sample slice\n",
    "                sample_idx = tuple(0 for _ in var_obj.shape)\n",
    "                sample_value = var_obj[sample_idx]\n",
    "                print(f\"    Sample value at {sample_idx}: {sample_value}\")\n",
    "                print(f\"    Shape: {var_obj.shape}\")\n",
    "            except Exception as e:\n",
    "                print(f\"    Could not read sample: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RESOLUTION COMPARISON\n",
      "============================================================\n",
      "\n",
      "TIF File:\n",
      "  Dimensions: 167551 x 144835\n",
      "  Resolution X: 0.00026949 degrees\n",
      "  Resolution Y: 0.00026949 degrees\n",
      "  Bounds: BoundingBox(left=-73.99593675196482, bottom=-33.75581376830244, right=-28.84184950111183, top=5.2764344843328335)\n",
      "  CRS: EPSG:4326\n",
      "\n",
      "NetCDF File:\n",
      "  Dimensions: 168 x 162\n",
      "  Resolution X: 0.25000000 degrees\n",
      "  Resolution Y: 0.25000000 degrees\n",
      "  Bounds: (-74.125, -34.125, -32.375, 6.125)\n",
      "  Coordinate variables: lon=lon, lat=lat\n",
      "\n",
      "============================================================\n",
      "COMPARISON:\n",
      "============================================================\n",
      "\n",
      "Resolution differences:\n",
      "  X: 0.2497305054 degrees\n",
      "  Y: 0.2497305054 degrees\n",
      "\n",
      "⚠ Resolutions differ\n",
      "  TIF resolution is 0.0011x in X direction\n",
      "  TIF resolution is 0.0011x in Y direction\n",
      "\n",
      "Dimension comparison:\n",
      "  TIF: 167551 x 144835 = 24,267,249,085 pixels\n",
      "  NC:  168 x 162 = 27,216 pixels\n",
      "  Ratio: 997.3274 x 894.0432\n",
      "\n",
      "Bounds comparison:\n",
      "  TIF: lon [-73.9959, -28.8418], lat [-33.7558, 5.2764]\n",
      "  NC:  lon [-74.1250, -32.3750], lat [-34.1250, 6.1250]\n",
      "  ✓ Bounds overlap\n"
     ]
    }
   ],
   "source": [
    "# Compare resolutions between TIF and NetCDF files\n",
    "print(\"=\"*60)\n",
    "print(\"RESOLUTION COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get TIF resolution\n",
    "with rasterio.open(tif_path) as tif_src:\n",
    "    tif_transform = tif_src.transform\n",
    "    tif_res_x = abs(tif_transform[0])\n",
    "    tif_res_y = abs(tif_transform[4])\n",
    "    tif_bounds = tif_src.bounds\n",
    "    tif_width = tif_src.width\n",
    "    tif_height = tif_src.height\n",
    "    tif_crs = tif_src.crs\n",
    "\n",
    "print(f\"\\nTIF File:\")\n",
    "print(f\"  Dimensions: {tif_width} x {tif_height}\")\n",
    "print(f\"  Resolution X: {tif_res_x:.8f} degrees\")\n",
    "print(f\"  Resolution Y: {tif_res_y:.8f} degrees\")\n",
    "print(f\"  Bounds: {tif_bounds}\")\n",
    "print(f\"  CRS: {tif_crs}\")\n",
    "\n",
    "# Get NetCDF resolution\n",
    "with nc.Dataset(nc_path, 'r') as nc_ds:\n",
    "    # Find lon/lat dimensions\n",
    "    dim_names = list(nc_ds.dimensions.keys())\n",
    "    lon_dim = next((d for d in dim_names if d.lower() in ['lon', 'longitude', 'x']), None)\n",
    "    lat_dim = next((d for d in dim_names if d.lower() in ['lat', 'latitude', 'y']), None)\n",
    "    \n",
    "    if lon_dim and lat_dim:\n",
    "        # Get coordinate values\n",
    "        if lon_dim in nc_ds.variables:\n",
    "            lon_vals = nc_ds.variables[lon_dim][:]\n",
    "        else:\n",
    "            lon_vals = np.arange(nc_ds.dimensions[lon_dim].size)\n",
    "            \n",
    "        if lat_dim in nc_ds.variables:\n",
    "            lat_vals = nc_ds.variables[lat_dim][:]\n",
    "        else:\n",
    "            lat_vals = np.arange(nc_ds.dimensions[lat_dim].size)\n",
    "        \n",
    "        # Calculate resolution\n",
    "        if len(lon_vals) > 1:\n",
    "            nc_res_x = abs(lon_vals[1] - lon_vals[0])\n",
    "        else:\n",
    "            nc_res_x = None\n",
    "            \n",
    "        if len(lat_vals) > 1:\n",
    "            nc_res_y = abs(lat_vals[1] - lat_vals[0])\n",
    "        else:\n",
    "            nc_res_y = None\n",
    "        \n",
    "        nc_width = len(lon_vals)\n",
    "        nc_height = len(lat_vals)\n",
    "        nc_bounds = (float(lon_vals.min()), float(lat_vals.min()), \n",
    "                     float(lon_vals.max()), float(lat_vals.max()))\n",
    "        \n",
    "        print(f\"\\nNetCDF File:\")\n",
    "        print(f\"  Dimensions: {nc_width} x {nc_height}\")\n",
    "        if nc_res_x is not None:\n",
    "            print(f\"  Resolution X: {nc_res_x:.8f} degrees\")\n",
    "        if nc_res_y is not None:\n",
    "            print(f\"  Resolution Y: {nc_res_y:.8f} degrees\")\n",
    "        print(f\"  Bounds: {nc_bounds}\")\n",
    "        print(f\"  Coordinate variables: lon={lon_dim}, lat={lat_dim}\")\n",
    "        \n",
    "        # Compare\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"COMPARISON:\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if nc_res_x is not None and nc_res_y is not None:\n",
    "            res_diff_x = abs(tif_res_x - nc_res_x)\n",
    "            res_diff_y = abs(tif_res_y - nc_res_y)\n",
    "            \n",
    "            print(f\"\\nResolution differences:\")\n",
    "            print(f\"  X: {res_diff_x:.10f} degrees\")\n",
    "            print(f\"  Y: {res_diff_y:.10f} degrees\")\n",
    "            \n",
    "            if res_diff_x < 1e-6 and res_diff_y < 1e-6:\n",
    "                print(f\"\\n✓ Resolutions match!\")\n",
    "            else:\n",
    "                print(f\"\\n⚠ Resolutions differ\")\n",
    "                print(f\"  TIF resolution is {tif_res_x/nc_res_x:.4f}x in X direction\")\n",
    "                print(f\"  TIF resolution is {tif_res_y/nc_res_y:.4f}x in Y direction\")\n",
    "        \n",
    "        # Compare dimensions\n",
    "        print(f\"\\nDimension comparison:\")\n",
    "        print(f\"  TIF: {tif_width} x {tif_height} = {tif_width * tif_height:,} pixels\")\n",
    "        print(f\"  NC:  {nc_width} x {nc_height} = {nc_width * nc_height:,} pixels\")\n",
    "        print(f\"  Ratio: {tif_width/nc_width:.4f} x {tif_height/nc_height:.4f}\")\n",
    "        \n",
    "        # Check bounds overlap\n",
    "        print(f\"\\nBounds comparison:\")\n",
    "        print(f\"  TIF: lon [{tif_bounds.left:.4f}, {tif_bounds.right:.4f}], \"\n",
    "              f\"lat [{tif_bounds.bottom:.4f}, {tif_bounds.top:.4f}]\")\n",
    "        print(f\"  NC:  lon [{nc_bounds[0]:.4f}, {nc_bounds[2]:.4f}], \"\n",
    "              f\"lat [{nc_bounds[1]:.4f}, {nc_bounds[3]:.4f}]\")\n",
    "        \n",
    "        # Check if bounds overlap\n",
    "        lon_overlap = not (tif_bounds.right < nc_bounds[0] or nc_bounds[2] < tif_bounds.left)\n",
    "        lat_overlap = not (tif_bounds.top < nc_bounds[1] or nc_bounds[3] < tif_bounds.bottom)\n",
    "        \n",
    "        if lon_overlap and lat_overlap:\n",
    "            print(f\"  ✓ Bounds overlap\")\n",
    "        else:\n",
    "            print(f\"  ⚠ Bounds do not overlap\")\n",
    "    else:\n",
    "        print(f\"\\n⚠ Could not find lon/lat dimensions in NetCDF file\")\n",
    "        print(f\"  Available dimensions: {dim_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRACTING NETCDF VARIABLES\n",
      "============================================================\n",
      "\n",
      "Output directories:\n",
      "  FWI_max: ../tests/tests_data/hazards/Fire/FWI/ensemble_return_period.nc\n",
      "  days_danger_total: ../tests/tests_data/hazards/Fire/days_danger_total/ensemble_return_period.nc\n",
      "\n",
      "Available data variables in source:\n",
      "  FWI_mean: shape (4, 4, 162, 168, 5), dtype float32\n",
      "  FWI_max: shape (4, 4, 162, 168, 5), dtype float32\n",
      "  days_low: shape (4, 4, 162, 168, 5), dtype float32\n",
      "  days_moderate: shape (4, 4, 162, 168, 5), dtype float32\n",
      "  days_high: shape (4, 4, 162, 168, 5), dtype float32\n",
      "  days_very_high: shape (4, 4, 162, 168, 5), dtype float32\n",
      "  days_extreme: shape (4, 4, 162, 168, 5), dtype float32\n",
      "  days_danger_total: shape (4, 4, 162, 168, 5), dtype float32\n",
      "\n",
      "Creating NetCDF file for FWI_max...\n",
      "  Output: ../tests/tests_data/hazards/Fire/FWI/ensemble_return_period.nc\n",
      "  ✓ Created NetCDF file for FWI_max\n",
      "    Variables: ['GWL', 'lon', 'lat', 'return_period', 'ensemble', 'FWI_max']\n",
      "\n",
      "Creating NetCDF file for days_danger_total...\n",
      "  Output: ../tests/tests_data/hazards/Fire/days_danger_total/ensemble_return_period.nc\n",
      "  ✓ Created NetCDF file for days_danger_total\n",
      "    Variables: ['GWL', 'lon', 'lat', 'return_period', 'ensemble', 'days_danger_total']\n"
     ]
    }
   ],
   "source": [
    "# Extract days_danger_total and FWI_max from NetCDF and save to separate files\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRACTING NETCDF VARIABLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Output directories - one per variable\n",
    "output_nc_dir_fwi = Path(\"../tests/tests_data/hazards/Fire/FWI\")\n",
    "output_nc_dir_fwi.mkdir(parents=True, exist_ok=True)\n",
    "output_nc_path_fwi = output_nc_dir_fwi / \"ensemble_return_period.nc\"\n",
    "\n",
    "output_nc_dir_days = Path(\"../tests/tests_data/hazards/Fire/days_danger_total\")\n",
    "output_nc_dir_days.mkdir(parents=True, exist_ok=True)\n",
    "output_nc_path_days = output_nc_dir_days / \"ensemble_return_period.nc\"\n",
    "\n",
    "print(f\"\\nOutput directories:\")\n",
    "print(f\"  FWI_max: {output_nc_path_fwi}\")\n",
    "print(f\"  days_danger_total: {output_nc_path_days}\")\n",
    "\n",
    "# Open source NetCDF\n",
    "with nc.Dataset(nc_path, 'r') as src_ds:\n",
    "    # Check available variables\n",
    "    print(f\"\\nAvailable data variables in source:\")\n",
    "    dim_names = list(src_ds.dimensions.keys())\n",
    "    data_vars = [v for v in src_ds.variables.keys() if v not in dim_names]\n",
    "    for var_name in data_vars:\n",
    "        var_obj = src_ds.variables[var_name]\n",
    "        print(f\"  {var_name}: shape {var_obj.shape}, dtype {var_obj.dtype}\")\n",
    "    \n",
    "    # Verify target variables exist\n",
    "    if 'days_danger_total' not in data_vars:\n",
    "        print(f\"\\n⚠ Warning: 'days_danger_total' not found in source file\")\n",
    "        print(f\"  Available variables: {data_vars}\")\n",
    "    if 'FWI_max' not in data_vars:\n",
    "        print(f\"\\n⚠ Warning: 'FWI_max' not found in source file\")\n",
    "        print(f\"  Available variables: {data_vars}\")\n",
    "    \n",
    "    # Function to create a NetCDF file with a single data variable\n",
    "    def create_nc_file_with_variable(output_path, var_name, src_ds):\n",
    "        \"\"\"Create a new NetCDF file containing only one data variable.\"\"\"\n",
    "        with nc.Dataset(output_path, 'w', format='NETCDF4') as dst_ds:\n",
    "            # Copy dimensions\n",
    "            for dim_name, dim_obj in src_ds.dimensions.items():\n",
    "                if dim_obj.isunlimited():\n",
    "                    dst_ds.createDimension(dim_name, None)\n",
    "                else:\n",
    "                    dst_ds.createDimension(dim_name, dim_obj.size)\n",
    "            \n",
    "            # Copy coordinate variables and their attributes\n",
    "            for coord_var_name in dim_names:\n",
    "                if coord_var_name in src_ds.variables:\n",
    "                    src_var = src_ds.variables[coord_var_name]\n",
    "                    fill_val = getattr(src_var, '_FillValue', None)\n",
    "                    dst_var = dst_ds.createVariable(\n",
    "                        coord_var_name, \n",
    "                        src_var.dtype, \n",
    "                        src_var.dimensions,\n",
    "                        fill_value=fill_val\n",
    "                    )\n",
    "                    dst_var[:] = src_var[:]\n",
    "                    \n",
    "                    # Copy attributes (skip _FillValue as it's already set)\n",
    "                    for attr in src_var.ncattrs():\n",
    "                        if attr != '_FillValue':\n",
    "                            setattr(dst_var, attr, getattr(src_var, attr))\n",
    "            \n",
    "            # Copy the target data variable\n",
    "            if var_name in src_ds.variables:\n",
    "                src_var = src_ds.variables[var_name]\n",
    "                \n",
    "                # Create variable in destination\n",
    "                dst_var = dst_ds.createVariable(\n",
    "                    var_name, \n",
    "                    src_var.dtype, \n",
    "                    src_var.dimensions,\n",
    "                    fill_value=getattr(src_var, '_FillValue', None)\n",
    "                )\n",
    "                \n",
    "                # Copy data\n",
    "                dst_var[:] = src_var[:]\n",
    "                \n",
    "                # Copy attributes (skip _FillValue as it's already set)\n",
    "                for attr in src_var.ncattrs():\n",
    "                    if attr != '_FillValue':\n",
    "                        setattr(dst_var, attr, getattr(src_var, attr))\n",
    "            \n",
    "            # Copy global attributes\n",
    "            for attr in src_ds.ncattrs():\n",
    "                setattr(dst_ds, attr, getattr(src_ds, attr))\n",
    "    \n",
    "    # Create file for FWI_max\n",
    "    if 'FWI_max' in data_vars:\n",
    "        print(f\"\\nCreating NetCDF file for FWI_max...\")\n",
    "        print(f\"  Output: {output_nc_path_fwi}\")\n",
    "        create_nc_file_with_variable(output_nc_path_fwi, 'FWI_max', src_ds)\n",
    "        print(f\"  ✓ Created NetCDF file for FWI_max\")\n",
    "        print(f\"    Variables: ['GWL', 'lon', 'lat', 'return_period', 'ensemble', 'FWI_max']\")\n",
    "    else:\n",
    "        print(f\"\\n⚠ Skipping FWI_max (variable not found)\")\n",
    "    \n",
    "    # Create file for days_danger_total\n",
    "    if 'days_danger_total' in data_vars:\n",
    "        print(f\"\\nCreating NetCDF file for days_danger_total...\")\n",
    "        print(f\"  Output: {output_nc_path_days}\")\n",
    "        create_nc_file_with_variable(output_nc_path_days, 'days_danger_total', src_ds)\n",
    "        print(f\"  ✓ Created NetCDF file for days_danger_total\")\n",
    "        print(f\"    Variables: ['GWL', 'lon', 'lat', 'return_period', 'ensemble', 'days_danger_total']\")\n",
    "    else:\n",
    "        print(f\"\\n⚠ Skipping days_danger_total (variable not found)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DOWNSAMPLING TIF FILE\n",
      "============================================================\n",
      "\n",
      "Output directory: ../tests/tests_data/hazards/Fire/land_cover\n",
      "Output file: ../tests/tests_data/hazards/Fire/land_cover/2024_brazil_land_cover.tif\n",
      "\n",
      "Output file does not exist. Starting downsampling...\n",
      "\n",
      "Source TIF properties:\n",
      "  Dimensions: 167551 x 144835\n",
      "  Resolution: 0.00026949 degrees\n",
      "\n",
      "Target TIF properties:\n",
      "  Dimensions: 41887 x 36208\n",
      "  Resolution: 0.00107798 degrees\n",
      "  Downsample factor: 4x\n",
      "\n",
      "Downsampling using mode (most common value) for categorical data...\n",
      "Reading full raster into memory...\n",
      "\n",
      "Processing band 1/1...\n",
      "  Reading source data...\n",
      "  Read complete (104.3s)\n",
      "  Downsampling (this may take a few minutes)...\n"
     ]
    }
   ],
   "source": [
    "# Downsample TIF by factor of 4 (using mode for categorical data)\n",
    "print(\"=\"*60)\n",
    "print(\"DOWNSAMPLING TIF FILE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Output directory\n",
    "output_tif_dir = Path(\"../tests/tests_data/hazards/Fire/land_cover\")\n",
    "output_tif_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_tif_path = output_tif_dir / \"2024_brazil_land_cover.tif\"\n",
    "\n",
    "print(f\"\\nOutput directory: {output_tif_dir}\")\n",
    "print(f\"Output file: {output_tif_path}\")\n",
    "\n",
    "# Check if file already exists\n",
    "if output_tif_path.exists():\n",
    "    print(f\"\\n✓ Output file already exists: {output_tif_path}\")\n",
    "    print(f\"  Skipping downsampling process.\")\n",
    "    \n",
    "    # Verify existing file\n",
    "    with rasterio.open(output_tif_path) as verify:\n",
    "        print(f\"\\nExisting file properties:\")\n",
    "        print(f\"  Dimensions: {verify.width} x {verify.height}\")\n",
    "        print(f\"  Resolution: {abs(verify.transform[0]):.8f} degrees\")\n",
    "        print(f\"  Bounds: {verify.bounds}\")\n",
    "else:\n",
    "    print(f\"\\nOutput file does not exist. Starting downsampling...\")\n",
    "    \n",
    "    downsample_factor = 4\n",
    "\n",
    "    def downsample_categorical_raster(data, factor, nodata=None):\n",
    "        \"\"\"\n",
    "        Downsample categorical raster using mode (most common value).\n",
    "        Fully vectorized implementation using numpy.apply_along_axis.\n",
    "        \n",
    "        Args:\n",
    "            data: 2D numpy array to downsample\n",
    "            factor: Downsampling factor (e.g., 4 means 4x4 pixels -> 1 pixel)\n",
    "            nodata: NoData value to exclude from mode calculation\n",
    "        \n",
    "        Returns:\n",
    "            Downsampled 2D numpy array\n",
    "        \"\"\"\n",
    "        height, width = data.shape\n",
    "        new_height = height // factor\n",
    "        new_width = width // factor\n",
    "        \n",
    "        # Crop to exact multiple of factor\n",
    "        crop_height = new_height * factor\n",
    "        crop_width = new_width * factor\n",
    "        data_cropped = data[:crop_height, :crop_width]\n",
    "        \n",
    "        # Reshape to group pixels into blocks: (new_h, factor, new_w, factor)\n",
    "        reshaped = data_cropped.reshape(new_height, factor, new_width, factor)\n",
    "        \n",
    "        # Transpose to: (new_h, new_w, factor, factor)\n",
    "        blocks = reshaped.transpose(0, 2, 1, 3)\n",
    "        \n",
    "        # Flatten each block: (new_h, new_w, factor*factor)\n",
    "        blocks_flat = blocks.reshape(new_height, new_width, factor * factor)\n",
    "        \n",
    "        # Use sentinel-based approach for maximum speed\n",
    "        # Replace nodata with sentinel, use vectorized mode, then restore nodata\n",
    "        if nodata is not None:\n",
    "            # Choose sentinel value that doesn't conflict with data\n",
    "            if np.issubdtype(data.dtype, np.integer):\n",
    "                # For integer types, use max possible value + 1\n",
    "                dtype_info = np.iinfo(data.dtype)\n",
    "                sentinel = dtype_info.max\n",
    "            else:\n",
    "                # For float, use a large negative number\n",
    "                sentinel = -999999.0\n",
    "            \n",
    "            # Create mask of all-nodata blocks\n",
    "            all_nodata_mask = np.all(blocks_flat == nodata, axis=2)\n",
    "            \n",
    "            # Replace nodata with sentinel temporarily\n",
    "            blocks_processed = np.where(blocks_flat == nodata, sentinel, blocks_flat)\n",
    "            \n",
    "            # Use vectorized scipy.stats.mode (much faster!)\n",
    "            print(f\"    Calculating mode (vectorized) for {new_height * new_width:,} pixels...\")\n",
    "            mode_result = stats.mode(blocks_processed, axis=2, keepdims=False, nan_policy='omit')\n",
    "            result = mode_result.mode.astype(data.dtype)\n",
    "            \n",
    "            # Restore nodata where all values were nodata\n",
    "            result[all_nodata_mask] = nodata\n",
    "            \n",
    "            # Also check if mode is sentinel (means all values in block were nodata)\n",
    "            # This handles edge cases where sentinel might accidentally be the mode\n",
    "            if np.issubdtype(data.dtype, np.integer):\n",
    "                sentinel_check = result == sentinel\n",
    "            else:\n",
    "                sentinel_check = np.isclose(result, sentinel)\n",
    "            result[sentinel_check] = nodata\n",
    "        else:\n",
    "            # No nodata - fully vectorized\n",
    "            print(f\"    Calculating mode (vectorized) for {new_height * new_width:,} pixels...\")\n",
    "            mode_result = stats.mode(blocks_flat, axis=2, keepdims=False)\n",
    "            result = mode_result.mode.astype(data.dtype)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        print(f\"\\nSource TIF properties:\")\n",
    "        print(f\"  Dimensions: {src.width} x {src.height}\")\n",
    "        print(f\"  Resolution: {abs(src.transform[0]):.8f} degrees\")\n",
    "        \n",
    "        # Calculate new dimensions\n",
    "        new_width = src.width // downsample_factor\n",
    "        new_height = src.height // downsample_factor\n",
    "        new_res = abs(src.transform[0]) * downsample_factor\n",
    "        \n",
    "        print(f\"\\nTarget TIF properties:\")\n",
    "        print(f\"  Dimensions: {new_width} x {new_height}\")\n",
    "        print(f\"  Resolution: {new_res:.8f} degrees\")\n",
    "        print(f\"  Downsample factor: {downsample_factor}x\")\n",
    "        \n",
    "        # Calculate new transform (resolution increased by factor)\n",
    "        new_transform = rasterio.Affine(\n",
    "            src.transform[0] * downsample_factor,  # pixel width\n",
    "            src.transform[1],\n",
    "            src.transform[2],\n",
    "            src.transform[3],\n",
    "            src.transform[4] * downsample_factor,  # pixel height (negative)\n",
    "            src.transform[5]\n",
    "        )\n",
    "        \n",
    "        # Create output profile\n",
    "        profile = src.profile.copy()\n",
    "        profile.update({\n",
    "            'width': new_width,\n",
    "            'height': new_height,\n",
    "            'transform': new_transform,\n",
    "            'compress': 'lzw',\n",
    "            'tiled': True\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nDownsampling using mode (most common value) for categorical data...\")\n",
    "        print(f\"Reading full raster into memory...\")\n",
    "        \n",
    "        # Initialize timing\n",
    "        start_time = time.time()\n",
    "        \n",
    "        with rasterio.open(output_tif_path, 'w', **profile) as dst:\n",
    "            for band_idx in range(1, src.count + 1):\n",
    "                band_start = time.time()\n",
    "                print(f\"\\nProcessing band {band_idx}/{src.count}...\")\n",
    "                \n",
    "                # Read entire band at once (faster than blocks for this operation)\n",
    "                print(f\"  Reading source data...\")\n",
    "                data = src.read(band_idx)\n",
    "                read_time = time.time() - band_start\n",
    "                print(f\"  Read complete ({read_time:.1f}s)\")\n",
    "                \n",
    "                # Downsample using vectorized mode calculation\n",
    "                print(f\"  Downsampling (this may take a few minutes)...\")\n",
    "                downsample_start = time.time()\n",
    "                nodata_val = src.nodata\n",
    "                \n",
    "                downsampled_data = downsample_categorical_raster(\n",
    "                    data, \n",
    "                    downsample_factor, \n",
    "                    nodata_val\n",
    "                )\n",
    "                \n",
    "                downsample_time = time.time() - downsample_start\n",
    "                print(f\"  Downsampling complete ({downsample_time:.1f}s)\")\n",
    "                \n",
    "                # Write downsampled data\n",
    "                print(f\"  Writing to file...\")\n",
    "                dst.write(downsampled_data, band_idx)\n",
    "                write_time = time.time() - downsample_start - downsample_time\n",
    "                \n",
    "                elapsed_time = time.time() - band_start\n",
    "                print(f\"  ✓ Band {band_idx} complete (total: {elapsed_time:.1f}s)\")\n",
    "                print(f\"    Breakdown: read={read_time:.1f}s, downsample={downsample_time:.1f}s, write={write_time:.1f}s\")\n",
    "        \n",
    "        print(f\"\\n✓ Created downsampled TIF file: {output_tif_path}\")\n",
    "        \n",
    "        # Verify output\n",
    "        with rasterio.open(output_tif_path) as verify:\n",
    "            print(f\"\\nVerification:\")\n",
    "            print(f\"  Dimensions: {verify.width} x {verify.height}\")\n",
    "            print(f\"  Resolution: {abs(verify.transform[0]):.8f} degrees\")\n",
    "            print(f\"  Bounds: {verify.bounds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
