{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory for CLIMBRA data\n",
    "inputs_base = \"../../workspace/demo_inputs\"\n",
    "climbra_base = Path(inputs_base) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc53e4",
   "metadata": {},
   "source": [
    "## Step 1: Explore a specific folder structure\n",
    "\n",
    "Let's pick the `Compound/FWI/ensemble` folder as an example to understand the file structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf4e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in ../../workspace/demo_inputs/Compound/FWI/ensemble:\n",
      "============================================================\n",
      "\n",
      "Total files: 0\n"
     ]
    }
   ],
   "source": [
    "# Pick a specific folder to explore\n",
    "example_folder = climbra_base / \"hazards\" / \"Compound\" / \"FWI\" / \"ensemble\"\n",
    "\n",
    "# List all files in this folder\n",
    "print(f\"Files in {example_folder}:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "files_info = []\n",
    "for file in sorted(example_folder.glob(\"*.nc\")):\n",
    "    file_size = file.stat().st_size / (1024 * 1024)  # Size in MB\n",
    "    files_info.append({\n",
    "        'filename': file.name,\n",
    "        'size_mb': f\"{file_size:.2f}\"\n",
    "    })\n",
    "    print(f\"  {file.name:45s} ({file_size:.2f} MB)\")\n",
    "\n",
    "print(f\"\\nTotal files: {len(files_info)}\")\n",
    "\n",
    "# Quick peek at one file structure\n",
    "if files_info:\n",
    "    sample_file = example_folder / files_info[0]['filename']\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Structure of {sample_file.name}:\")\n",
    "    print(\"=\" * 60)\n",
    "    ds = xr.open_dataset(sample_file)\n",
    "    print(ds)\n",
    "    ds.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221c444",
   "metadata": {},
   "source": [
    "## Step 2: Find all files matching `*_return_periods.nc` pattern\n",
    "\n",
    "Now let's search across all CLIMBRA folders for files matching the pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "386ae893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 files matching '*_return_periods.nc' pattern:\n",
      "================================================================================\n",
      "  hazards/Compound/FWI/ensemble/ensemble_return_periods.nc     (2.57 MB)\n",
      "  hazards/Compound/HI/ensemble/ensemble_return_period.nc       (2.55 MB)\n",
      "  hazards/Drought/CDD/ensemble/ensemble_return_period.nc       (2.83 MB)\n",
      "  hazards/Drought/SPI6/ensemble/ensemble_return_period.nc      (2.66 MB)\n",
      "  hazards/ExtremeRainfall/CWD/ensemble/ensemble_return_period.nc (2.90 MB)\n",
      "  hazards/ExtremeRainfall/Rx1day/ensemble/ensemble_return_period.nc (2.87 MB)\n",
      "  hazards/ExtremeRainfall/Rx5day/ensemble/ensemble_return_period.nc (2.79 MB)\n",
      "  hazards/Flood/GIRI_flood_depth_cube.nc                       (7539.85 MB)\n",
      "  hazards/Heat/Frost/ensemble/ensemble_return_period.nc        (0.95 MB)\n",
      "  hazards/Heat/TNN/ensemble/ensemble_return_period.nc          (2.78 MB)\n",
      "  hazards/Heat/TXX/ensemble/ensemble_return_period.nc          (2.32 MB)\n"
     ]
    }
   ],
   "source": [
    "# Find all files matching *_return_periods.nc pattern\n",
    "return_period_files_1 = list(climbra_base.glob(\"**/ensemble/*ensemble_return_periods.nc\"))\n",
    "return_period_files_2 = list(climbra_base.glob(\"**/ensemble/*ensemble_return_period.nc\"))\n",
    "return_period_files_3 = list(climbra_base.glob(\"**/Flood/GIRI_flood_depth_cube.nc\"))\n",
    "return_period_files = return_period_files_1 + return_period_files_2 + return_period_files_3\n",
    "\n",
    "print(f\"Found {len(return_period_files)} files matching '*_return_periods.nc' pattern:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for file in sorted(return_period_files):\n",
    "    # Get relative path from climbra_base\n",
    "    rel_path = file.relative_to(climbra_base)\n",
    "    file_size = file.stat().st_size / (1024 * 1024)  # Size in MB\n",
    "    print(f\"  {str(rel_path):60s} ({file_size:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2133a4",
   "metadata": {},
   "source": [
    "## Step 3: Load all return period files into a dictionary\n",
    "\n",
    "We'll organize the data by hazard type and model type (ensemble vs individual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4898efdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading return period datasets...\n",
      "================================================================================\n",
      "✓ Loaded: hazards/Compound/FWI/ensemble_return_periods.nc\n",
      "✓ Loaded: hazards/Compound/HI/ensemble_return_period.nc\n",
      "✓ Loaded: hazards/Drought/CDD/ensemble_return_period.nc\n",
      "✓ Loaded: hazards/Drought/SPI6/ensemble_return_period.nc\n",
      "✓ Loaded: hazards/ExtremeRainfall/CWD/ensemble_return_period.nc\n",
      "✓ Loaded: hazards/ExtremeRainfall/Rx1day/ensemble_return_period.nc\n",
      "✓ Loaded: hazards/ExtremeRainfall/Rx5day/ensemble_return_period.nc\n",
      "✓ Loaded: hazards/Flood/GIRI_flood_depth_cube.nc/GIRI_flood_depth_cube.nc\n",
      "✓ Loaded: hazards/Heat/Frost/ensemble_return_period.nc\n",
      "✓ Loaded: hazards/Heat/TNN/ensemble_return_period.nc\n",
      "✓ Loaded: hazards/Heat/TXX/ensemble_return_period.nc\n",
      "\n",
      "================================================================================\n",
      "Successfully loaded 11 return period datasets\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load all return period files into a structured dictionary\n",
    "return_period_data = {}\n",
    "\n",
    "print(\"Loading return period datasets...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for file in sorted(return_period_files):\n",
    "    # Parse the path to extract metadata\n",
    "    parts = file.relative_to(climbra_base).parts\n",
    "    \n",
    "    # Create a hierarchical key structure\n",
    "    # e.g., \"Compound/FWI/ensemble\"\n",
    "    category = parts[0]  # e.g., \"Compound\", \"Drought\", \"Heat\"\n",
    "    hazard = parts[1] if len(parts) > 1 else \"unknown\"  # e.g., \"FWI\", \"CDD\"\n",
    "    model_type = parts[2] if len(parts) > 2 else \"unknown\"  # e.g., \"ensemble\", \"individual_models\"\n",
    "    filename = file.name\n",
    "    \n",
    "    # Create nested structure\n",
    "    if category not in return_period_data:\n",
    "        return_period_data[category] = {}\n",
    "    if hazard not in return_period_data[category]:\n",
    "        return_period_data[category][hazard] = {}\n",
    "    if model_type not in return_period_data[category][hazard]:\n",
    "        return_period_data[category][hazard][model_type] = {}\n",
    "    \n",
    "    # Load the dataset\n",
    "    try:\n",
    "        ds = xr.open_dataset(file)\n",
    "        return_period_data[category][hazard][model_type][filename] = ds\n",
    "        print(f\"✓ Loaded: {category}/{hazard}/{model_type}/{filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to load {file}: {e}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Successfully loaded {len(return_period_files)} return period datasets\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e95f544",
   "metadata": {},
   "source": [
    "## Step 4: Explore the loaded data structure\n",
    "\n",
    "Let's see what we have loaded and examine one dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2546983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data structure:\n",
      "================================================================================\n",
      "\n",
      "hazards/\n",
      "  Compound/\n",
      "    FWI/ (1 files)\n",
      "      - ensemble_return_periods.nc\n",
      "    HI/ (1 files)\n",
      "      - ensemble_return_period.nc\n",
      "  Drought/\n",
      "    CDD/ (1 files)\n",
      "      - ensemble_return_period.nc\n",
      "    SPI6/ (1 files)\n",
      "      - ensemble_return_period.nc\n",
      "  ExtremeRainfall/\n",
      "    CWD/ (1 files)\n",
      "      - ensemble_return_period.nc\n",
      "    Rx1day/ (1 files)\n",
      "      - ensemble_return_period.nc\n",
      "    Rx5day/ (1 files)\n",
      "      - ensemble_return_period.nc\n",
      "  Flood/\n",
      "    GIRI_flood_depth_cube.nc/ (1 files)\n",
      "      - GIRI_flood_depth_cube.nc\n",
      "  Heat/\n",
      "    Frost/ (1 files)\n",
      "      - ensemble_return_period.nc\n",
      "    TNN/ (1 files)\n",
      "      - ensemble_return_period.nc\n",
      "    TXX/ (1 files)\n",
      "      - ensemble_return_period.nc\n"
     ]
    }
   ],
   "source": [
    "# Display the structure of loaded data\n",
    "print(\"Data structure:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for category in return_period_data:\n",
    "    print(f\"\\n{category}/\")\n",
    "    for hazard in return_period_data[category]:\n",
    "        print(f\"  {hazard}/\")\n",
    "        for model_type in return_period_data[category][hazard]:\n",
    "            files = list(return_period_data[category][hazard][model_type].keys())\n",
    "            print(f\"    {model_type}/ ({len(files)} files)\")\n",
    "            for file in files:\n",
    "                print(f\"      - {file}\")\n",
    "\n",
    "# Access example: Get the FWI ensemble return periods dataset\n",
    "if 'Compound' in return_period_data and 'FWI' in return_period_data['Compound']:\n",
    "    if 'ensemble' in return_period_data['Compound']['FWI']:\n",
    "        example_ds = list(return_period_data['Compound']['FWI']['ensemble'].values())[0]\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"Example dataset (Compound/FWI/ensemble):\")\n",
    "        print(\"=\" * 80)\n",
    "        print(example_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c4f2a7",
   "metadata": {},
   "source": [
    "## Accessing the Data\n",
    "\n",
    "You can now access the loaded datasets using the hierarchical structure:\n",
    "\n",
    "```python\n",
    "# Access specific dataset\n",
    "ds = return_period_data['Compound']['FWI']['ensemble']['ensemble_return_periods.nc']\n",
    "\n",
    "# Or iterate through all datasets\n",
    "for category in return_period_data:\n",
    "    for hazard in return_period_data[category]:\n",
    "        for model_type in return_period_data[category][hazard]:\n",
    "            for filename, dataset in return_period_data[category][hazard][model_type].items():\n",
    "                # Do something with dataset\n",
    "                pass\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35dbd6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 9MB\n",
      "Dimensions:        (ensemble: 4, GWL: 4, lat: 162, lon: 168, return_period: 5)\n",
      "Coordinates:\n",
      "  * ensemble       (ensemble) <U6 96B 'mean' 'median' 'p10' 'p90'\n",
      "  * GWL            (GWL) <U7 112B 'present' '1.5' '2' '3'\n",
      "  * lat            (lat) float64 1kB -34.12 -33.88 -33.62 ... 5.625 5.875 6.125\n",
      "  * lon            (lon) float64 1kB -74.12 -73.88 -73.62 ... -32.62 -32.38\n",
      "  * return_period  (return_period) int64 40B 5 10 25 50 100\n",
      "Data variables:\n",
      "    FWI_max        (ensemble, GWL, lat, lon, return_period) float32 9MB ...\n",
      "<xarray.Dataset> Size: 9MB\n",
      "Dimensions:        (ensemble: 4, GWL: 4, return_period: 5, lat: 162, lon: 168)\n",
      "Coordinates:\n",
      "  * ensemble       (ensemble) <U6 96B 'mean' 'median' 'p10' 'p90'\n",
      "  * GWL            (GWL) <U7 112B 'present' '1.5' '2' '3'\n",
      "  * return_period  (return_period) int64 40B 5 10 25 50 100\n",
      "  * lat            (lat) float64 1kB -34.12 -33.88 -33.62 ... 5.625 5.875 6.125\n",
      "  * lon            (lon) float64 1kB -74.12 -73.88 -73.62 ... -32.62 -32.38\n",
      "Data variables:\n",
      "    HI_max         (ensemble, GWL, return_period, lat, lon) float32 9MB ...\n",
      "<xarray.Dataset> Size: 9MB\n",
      "Dimensions:        (ensemble: 4, GWL: 4, return_period: 5, lat: 162, lon: 168)\n",
      "Coordinates:\n",
      "  * ensemble       (ensemble) <U6 96B 'mean' 'median' 'p10' 'p90'\n",
      "  * GWL            (GWL) <U7 112B 'present' '1.5' '2' '3'\n",
      "  * return_period  (return_period) int64 40B 5 10 25 50 100\n",
      "  * lat            (lat) float64 1kB -34.12 -33.88 -33.62 ... 5.625 5.875 6.125\n",
      "  * lon            (lon) float64 1kB -74.12 -73.88 -73.62 ... -32.62 -32.38\n",
      "Data variables:\n",
      "    CDD            (ensemble, GWL, return_period, lat, lon) float32 9MB ...\n",
      "<xarray.Dataset> Size: 9MB\n",
      "Dimensions:        (ensemble: 4, GWL: 4, return_period: 5, lat: 162, lon: 168)\n",
      "Coordinates:\n",
      "  * ensemble       (ensemble) <U6 96B 'mean' 'median' 'p10' 'p90'\n",
      "  * GWL            (GWL) <U7 112B 'present' '1.5' '2' '3'\n",
      "  * return_period  (return_period) int64 40B 5 10 25 50 100\n",
      "  * lat            (lat) float64 1kB -34.12 -33.88 -33.62 ... 5.625 5.875 6.125\n",
      "  * lon            (lon) float64 1kB -74.12 -73.88 -73.62 ... -32.62 -32.38\n",
      "Data variables:\n",
      "    SPI6           (ensemble, GWL, return_period, lat, lon) float32 9MB ...\n",
      "<xarray.Dataset> Size: 9MB\n",
      "Dimensions:        (ensemble: 4, GWL: 4, return_period: 5, lat: 162, lon: 168)\n",
      "Coordinates:\n",
      "  * ensemble       (ensemble) <U6 96B 'mean' 'median' 'p10' 'p90'\n",
      "  * GWL            (GWL) <U7 112B 'present' '1.5' '2' '3'\n",
      "  * return_period  (return_period) int64 40B 5 10 25 50 100\n",
      "  * lat            (lat) float64 1kB -34.12 -33.88 -33.62 ... 5.625 5.875 6.125\n",
      "  * lon            (lon) float64 1kB -74.12 -73.88 -73.62 ... -32.62 -32.38\n",
      "Data variables:\n",
      "    CWD            (ensemble, GWL, return_period, lat, lon) float32 9MB ...\n",
      "<xarray.Dataset> Size: 9MB\n",
      "Dimensions:        (ensemble: 4, GWL: 4, return_period: 5, lat: 162, lon: 168)\n",
      "Coordinates:\n",
      "  * ensemble       (ensemble) <U6 96B 'mean' 'median' 'p10' 'p90'\n",
      "  * GWL            (GWL) <U7 112B 'present' '1.5' '2' '3'\n",
      "  * return_period  (return_period) int64 40B 5 10 25 50 100\n",
      "  * lat            (lat) float64 1kB -34.12 -33.88 -33.62 ... 5.625 5.875 6.125\n",
      "  * lon            (lon) float64 1kB -74.12 -73.88 -73.62 ... -32.62 -32.38\n",
      "Data variables:\n",
      "    Rx1day         (ensemble, GWL, return_period, lat, lon) float32 9MB ...\n",
      "<xarray.Dataset> Size: 9MB\n",
      "Dimensions:        (ensemble: 4, GWL: 4, return_period: 5, lat: 162, lon: 168)\n",
      "Coordinates:\n",
      "  * ensemble       (ensemble) <U6 96B 'mean' 'median' 'p10' 'p90'\n",
      "  * GWL            (GWL) <U7 112B 'present' '1.5' '2' '3'\n",
      "  * return_period  (return_period) int64 40B 5 10 25 50 100\n",
      "  * lat            (lat) float64 1kB -34.12 -33.88 -33.62 ... 5.625 5.875 6.125\n",
      "  * lon            (lon) float64 1kB -74.12 -73.88 -73.62 ... -32.62 -32.38\n",
      "Data variables:\n",
      "    Rx5day         (ensemble, GWL, return_period, lat, lon) float32 9MB ...\n",
      "<xarray.Dataset> Size: 245GB\n",
      "Dimensions:        (scenario: 3, return_period: 7, lat: 54000, lon: 54000)\n",
      "Coordinates:\n",
      "  * scenario       (scenario) <U15 180B 'Present Climate' 'SSP1-2.6' 'SSP5-8.5'\n",
      "  * return_period  (return_period) int64 56B 2 5 25 50 100 200 500\n",
      "  * lat            (lat) float64 432kB 10.0 9.999 9.998 ... -35.0 -35.0 -35.0\n",
      "  * lon            (lon) float64 432kB -75.0 -75.0 -75.0 ... -30.0 -30.0 -30.0\n",
      "    spatial_ref    int64 8B ...\n",
      "Data variables:\n",
      "    flood_depth    (scenario, return_period, lat, lon) float32 245GB ...\n",
      "Attributes:\n",
      "    long_name:  Flood depth\n",
      "    units:      m\n",
      "    source:     UNEP GRID hazards data\n",
      "    note:       Cropped to South America; scenarios labelled by human-readabl...\n",
      "<xarray.Dataset> Size: 9MB\n",
      "Dimensions:        (ensemble: 4, GWL: 4, return_period: 5, lat: 162, lon: 168)\n",
      "Coordinates:\n",
      "  * ensemble       (ensemble) <U6 96B 'mean' 'median' 'p10' 'p90'\n",
      "  * GWL            (GWL) <U7 112B 'present' '1.5' '2' '3'\n",
      "  * return_period  (return_period) int64 40B 5 10 25 50 100\n",
      "  * lat            (lat) float64 1kB -34.12 -33.88 -33.62 ... 5.625 5.875 6.125\n",
      "  * lon            (lon) float64 1kB -74.12 -73.88 -73.62 ... -32.62 -32.38\n",
      "Data variables:\n",
      "    Frost          (ensemble, GWL, return_period, lat, lon) float32 9MB ...\n",
      "<xarray.Dataset> Size: 9MB\n",
      "Dimensions:        (ensemble: 4, GWL: 4, return_period: 5, lat: 162, lon: 168)\n",
      "Coordinates:\n",
      "  * ensemble       (ensemble) <U6 96B 'mean' 'median' 'p10' 'p90'\n",
      "  * GWL            (GWL) <U7 112B 'present' '1.5' '2' '3'\n",
      "  * return_period  (return_period) int64 40B 5 10 25 50 100\n",
      "  * lat            (lat) float64 1kB -34.12 -33.88 -33.62 ... 5.625 5.875 6.125\n",
      "  * lon            (lon) float64 1kB -74.12 -73.88 -73.62 ... -32.62 -32.38\n",
      "Data variables:\n",
      "    TNN            (ensemble, GWL, return_period, lat, lon) float32 9MB ...\n",
      "<xarray.Dataset> Size: 9MB\n",
      "Dimensions:        (ensemble: 4, GWL: 4, return_period: 5, lat: 162, lon: 168)\n",
      "Coordinates:\n",
      "  * ensemble       (ensemble) <U6 96B 'mean' 'median' 'p10' 'p90'\n",
      "  * GWL            (GWL) <U7 112B 'present' '1.5' '2' '3'\n",
      "  * return_period  (return_period) int64 40B 5 10 25 50 100\n",
      "  * lat            (lat) float64 1kB -34.12 -33.88 -33.62 ... 5.625 5.875 6.125\n",
      "  * lon            (lon) float64 1kB -74.12 -73.88 -73.62 ... -32.62 -32.38\n",
      "Data variables:\n",
      "    TXX            (ensemble, GWL, return_period, lat, lon) float32 9MB ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Or iterate through all datasets\n",
    "for category in return_period_data:\n",
    "    for hazard in return_period_data[category]:\n",
    "        for model_type in return_period_data[category][hazard]:\n",
    "            for filename, dataset in return_period_data[category][hazard][model_type].items():\n",
    "                # Do something with dataset\n",
    "                print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711daace",
   "metadata": {},
   "source": [
    "## Step 5: Copy files to demo_inputs/hazards\n",
    "\n",
    "\n",
    "Copy all return period files to `workspace/demo_inputs/hazards` while preserving the folder structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba9f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 11 files to demo_inputs/hazards\n",
      "================================================================================\n",
      "✓ Copied: hazards/Compound/FWI/ensemble/ensemble_return_periods.nc\n",
      "✓ Copied: hazards/Compound/HI/ensemble/ensemble_return_period.nc\n",
      "✓ Copied: hazards/Drought/CDD/ensemble/ensemble_return_period.nc\n",
      "✓ Copied: hazards/Drought/SPI6/ensemble/ensemble_return_period.nc\n",
      "✓ Copied: hazards/ExtremeRainfall/CWD/ensemble/ensemble_return_period.nc\n",
      "✓ Copied: hazards/ExtremeRainfall/Rx1day/ensemble/ensemble_return_period.nc\n",
      "✓ Copied: hazards/ExtremeRainfall/Rx5day/ensemble/ensemble_return_period.nc\n",
      "✓ Copied: hazards/Flood/GIRI_flood_depth_cube.nc\n",
      "✓ Copied: hazards/Heat/Frost/ensemble/ensemble_return_period.nc\n",
      "✓ Copied: hazards/Heat/TNN/ensemble/ensemble_return_period.nc\n",
      "✓ Copied: hazards/Heat/TXX/ensemble/ensemble_return_period.nc\n",
      "\n",
      "================================================================================\n",
      "Summary:\n",
      "  Successfully copied: 11 files\n",
      "  Failed: 0 files\n",
      "  Destination: /Users/bertrandgallice/code/Theia-Finance-Labs/climate.risk.tool/data-raw/notebooks/demo_inputs/hazards\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Define destination directory\n",
    "dest_base = Path(inputs_base) / \"hazards\"\n",
    "\n",
    "print(f\"Copying {len(return_period_files)} files to {dest_base}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Copy each file while preserving folder structure\n",
    "copied_count = 0\n",
    "failed_count = 0\n",
    "\n",
    "for file in sorted(return_period_files):\n",
    "    # Get relative path from CLIMBRA base\n",
    "    rel_path = file.relative_to(climbra_base)\n",
    "    \n",
    "    # Create destination path\n",
    "    dest_file = dest_base / rel_path\n",
    "    \n",
    "    # Create parent directories if they don't exist\n",
    "    dest_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Copy the file\n",
    "        shutil.copy2(file, dest_file)\n",
    "        copied_count += 1\n",
    "        print(f\"✓ Copied: {rel_path}\")\n",
    "    except Exception as e:\n",
    "        failed_count += 1\n",
    "        print(f\"✗ Failed to copy {rel_path}: {e}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Summary:\")\n",
    "print(f\"  Successfully copied: {copied_count} files\")\n",
    "print(f\"  Failed: {failed_count} files\")\n",
    "print(f\"  Destination: {dest_base.absolute()}\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e05a638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
