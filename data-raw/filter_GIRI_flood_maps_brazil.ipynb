{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter GIRI Flood Maps for Brazil\n",
    "\n",
    "Simple clip to Brazil boundaries - no aggregation, maintains original resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying 50km buffer...\n",
      "Buffered bounds: [-74.43960587 -34.12331173 -28.40041271   5.71770308]\n",
      "Brazil boundaries bounds: [-73.99046792 -33.75076853 -28.84916792   5.27113147]\n",
      "Easternmost longitude: -28.849167916992187\n",
      "(Fernando de Noronha is at ~-32.38°E, so this should be >= -32.38)\n",
      "Found 24 TIFF files to process\n",
      "Skipping flood_pc_100_glob.tif (already exists)\n",
      "Processing: flood_pc_10_glob.tif\n",
      "   Original size: 3.18 GB\n",
      "   Original dimensions: 432000 x 216000\n",
      "   Original bounds: BoundingBox(left=-180.0, bottom=-90.0, right=180.0, top=90.0)\n",
      "   Original dtype: uint32\n",
      "   Original nodata: 0.0\n",
      "   Clipped dimensions: 55248 x 47810\n",
      "   Verifying output integrity...\n",
      "   Output dtype: uint32 (should match original)\n",
      "   Output nodata: 0.0 (should match original)\n",
      "   Data range: [0.000000, 10428.000000]\n",
      "   Clipped size: 0.18 GB\n",
      "   Size reduction: 94.5%\n",
      "   ✓ Saved to: /Users/bertrandgallice/code/Theia-Finance-Labs/climate.risk.tool/workspace/GIRI_raw/brazil/flood_pc_10_glob.tif\n",
      "\n",
      "Skipping flood_pc_200_glob.tif (already exists)\n",
      "Skipping flood_pc_25_glob.tif (already exists)\n",
      "Skipping flood_pc_2_glob.tif (already exists)\n",
      "Skipping flood_pc_500_glob.tif (already exists)\n",
      "Skipping flood_pc_50_glob.tif (already exists)\n",
      "Skipping flood_pc_5_glob.tif (already exists)\n",
      "Skipping flood_rcp26_100_glob.tif (already exists)\n",
      "Processing: flood_rcp26_10_glob.tif\n",
      "   Original size: 3.13 GB\n",
      "   Original dimensions: 432000 x 216000\n",
      "   Original bounds: BoundingBox(left=-180.0, bottom=-90.0, right=180.0, top=90.0)\n",
      "   Original dtype: uint32\n",
      "   Original nodata: 0.0\n",
      "   Clipped dimensions: 55248 x 47810\n",
      "   Verifying output integrity...\n",
      "   Output dtype: uint32 (should match original)\n",
      "   Output nodata: 0.0 (should match original)\n",
      "   Data range: [0.000000, 10255.000000]\n",
      "   Clipped size: 0.18 GB\n",
      "   Size reduction: 94.3%\n",
      "   ✓ Saved to: /Users/bertrandgallice/code/Theia-Finance-Labs/climate.risk.tool/workspace/GIRI_raw/brazil/flood_rcp26_10_glob.tif\n",
      "\n",
      "Skipping flood_rcp26_200_glob.tif (already exists)\n",
      "Skipping flood_rcp26_25_glob.tif (already exists)\n",
      "Skipping flood_rcp26_2_glob.tif (already exists)\n",
      "Skipping flood_rcp26_500_glob.tif (already exists)\n",
      "Skipping flood_rcp26_50_glob.tif (already exists)\n",
      "Skipping flood_rcp26_5_glob.tif (already exists)\n",
      "Skipping flood_rcp85_100_glob.tif (already exists)\n",
      "Processing: flood_rcp85_10_glob.tif\n",
      "   Original size: 3.25 GB\n",
      "   Original dimensions: 432000 x 216000\n",
      "   Original bounds: BoundingBox(left=-180.0, bottom=-90.0, right=180.0, top=90.0)\n",
      "   Original dtype: uint32\n",
      "   Original nodata: 0.0\n",
      "   Clipped dimensions: 55248 x 47810\n",
      "   Verifying output integrity...\n",
      "   Output dtype: uint32 (should match original)\n",
      "   Output nodata: 0.0 (should match original)\n",
      "   Data range: [0.000000, 9995.000000]\n",
      "   Clipped size: 0.18 GB\n",
      "   Size reduction: 94.4%\n",
      "   ✓ Saved to: /Users/bertrandgallice/code/Theia-Finance-Labs/climate.risk.tool/workspace/GIRI_raw/brazil/flood_rcp85_10_glob.tif\n",
      "\n",
      "Skipping flood_rcp85_200_glob.tif (already exists)\n",
      "Skipping flood_rcp85_25_glob.tif (already exists)\n",
      "Skipping flood_rcp85_2_glob.tif (already exists)\n",
      "Skipping flood_rcp85_500_glob.tif (already exists)\n",
      "Skipping flood_rcp85_50_glob.tif (already exists)\n",
      "Skipping flood_rcp85_5_glob.tif (already exists)\n",
      "Processing complete\n",
      "Output files saved in: /Users/bertrandgallice/code/Theia-Finance-Labs/climate.risk.tool/workspace/GIRI_raw/brazil\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Define paths\n",
    "project_root = Path().resolve().parent\n",
    "giri_raw_dir = project_root / 'workspace' / 'GIRI_raw'\n",
    "# Use ADM2 boundaries to ensure all municipalities (including Fernando de Noronha) are included\n",
    "# ADM1 boundaries only extend to -34.66°E, but Fernando de Noronha extends to -32.38°E\n",
    "brazil_boundaries_file = project_root / 'workspace' / \"Brazil Borders\" / \"geoBoundaries-BRA-ADM0-all\" / \"geoBoundaries-BRA-ADM0.shp\"\n",
    "output_dir = giri_raw_dir / 'brazil'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Load Brazil boundaries (ADM2 includes all municipalities including Fernando de Noronha)\n",
    "brazil_gdf = gpd.read_file(brazil_boundaries_file)\n",
    "brazil_union = brazil_gdf.geometry.union_all()\n",
    "\n",
    "buffer_km = 50\n",
    "buffer_m = buffer_km * 1000\n",
    "\n",
    "print(f\"\\nApplying {buffer_km}km buffer...\")\n",
    "# Project to metric CRS (EPSG:3857) for accurate buffering in meters\n",
    "brazil_metric = gpd.GeoSeries([brazil_union], crs=brazil_gdf.crs).to_crs(\"EPSG:3857\")\n",
    "brazil_buffered_metric = brazil_metric.buffer(buffer_m)\n",
    "# Project back to original CRS\n",
    "brazil_buffered = brazil_buffered_metric.to_crs(brazil_gdf.crs)\n",
    "brazil_union = brazil_buffered.iloc[0]\n",
    "\n",
    "print(f\"Buffered bounds: {brazil_buffered.total_bounds}\")\n",
    "\n",
    "# Verify the bounds include Fernando de Noronha\n",
    "print(f\"Brazil boundaries bounds: {brazil_gdf.total_bounds}\")\n",
    "print(f\"Easternmost longitude: {brazil_gdf.total_bounds[2]}\")\n",
    "print(f\"(Fernando de Noronha is at ~-32.38°E, so this should be >= -32.38)\")\n",
    "\n",
    "# Find all TIFF files\n",
    "tif_files = sorted(glob.glob(str(giri_raw_dir / '*.tif')))\n",
    "\n",
    "print(f'Found {len(tif_files)} TIFF files to process')\n",
    "\n",
    "# Process each file\n",
    "for tif_file in tif_files:\n",
    "    tif_name = Path(tif_file).name\n",
    "    output_file = output_dir / tif_name\n",
    "    \n",
    "    if output_file.exists():\n",
    "        print(f'Skipping {tif_name} (already exists)')\n",
    "        continue\n",
    "    \n",
    "    print(f'Processing: {tif_name}')\n",
    "    \n",
    "    # Get original file size\n",
    "    original_size_gb = os.path.getsize(tif_file) / (1024**3)\n",
    "    print(f'   Original size: {original_size_gb:.2f} GB')\n",
    "    \n",
    "    with rasterio.open(tif_file) as src:\n",
    "        print(f'   Original dimensions: {src.width} x {src.height}')\n",
    "        print(f'   Original bounds: {src.bounds}')\n",
    "        print(f'   Original dtype: {src.dtypes[0]}')\n",
    "        print(f'   Original nodata: {src.nodata}')\n",
    "        \n",
    "        # Reproject Brazil geometry to match raster CRS\n",
    "        if brazil_gdf.crs != src.crs:\n",
    "            brazil_reprojected = gpd.GeoSeries([brazil_union], crs=brazil_gdf.crs).to_crs(src.crs)\n",
    "            brazil_geom = brazil_reprojected.iloc[0]\n",
    "        else:\n",
    "            brazil_geom = brazil_union\n",
    "        \n",
    "        # Clip the raster - crop=True reduces extent, filled=False preserves nodata\n",
    "        # This keeps EXACT same values, just crops spatial extent\n",
    "        out_image, out_transform = mask(src, [brazil_geom], crop=True, filled=False)\n",
    "        \n",
    "        print(f'   Clipped dimensions: {out_image.shape[2]} x {out_image.shape[1]}')\n",
    "        \n",
    "        # Preserve ALL original metadata for exact value reproduction\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            'driver': 'GTiff',\n",
    "            'height': out_image.shape[1],\n",
    "            'width': out_image.shape[2],\n",
    "            'transform': out_transform,\n",
    "            # Compression settings - these don't change values, just file size\n",
    "            'compress': 'DEFLATE',\n",
    "            'predictor': 2,  # Works with DEFLATE for numeric data\n",
    "            'tiled': True,\n",
    "            'blockxsize': 256,\n",
    "            'blockysize': 256,\n",
    "            'ZLEVEL': 9\n",
    "        })\n",
    "        \n",
    "        # Write with exact same data type and nodata value\n",
    "        with rasterio.open(output_file, 'w', **out_meta) as dst:\n",
    "            dst.write(out_image)\n",
    "    \n",
    "    # Verify the output\n",
    "    print(f'   Verifying output integrity...')\n",
    "    with rasterio.open(output_file) as verify:\n",
    "        print(f'   Output dtype: {verify.dtypes[0]} (should match original)')\n",
    "        print(f'   Output nodata: {verify.nodata} (should match original)')\n",
    "        \n",
    "        # Read a sample to check value range\n",
    "        sample = verify.read(1)\n",
    "        valid_data = sample[~np.isnan(sample)] if np.isnan(verify.nodata or np.nan) else sample[sample != verify.nodata]\n",
    "        if len(valid_data) > 0:\n",
    "            print(f'   Data range: [{valid_data.min():.6f}, {valid_data.max():.6f}]')\n",
    "    \n",
    "    # Get output file size\n",
    "    output_size_gb = os.path.getsize(output_file) / (1024**3)\n",
    "    print(f'   Clipped size: {output_size_gb:.2f} GB')\n",
    "    \n",
    "    if output_size_gb < original_size_gb:\n",
    "        reduction_pct = (1 - output_size_gb / original_size_gb) * 100\n",
    "        print(f'   Size reduction: {reduction_pct:.1f}%')\n",
    "    else:\n",
    "        increase_pct = (output_size_gb / original_size_gb - 1) * 100\n",
    "        print(f'   WARNING: Size increased by {increase_pct:.1f}%!')\n",
    "    \n",
    "    print(f'   ✓ Saved to: {output_file}')\n",
    "    print()\n",
    "\n",
    "print('Processing complete')\n",
    "print(f'Output files saved in: {output_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_pc_500_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_pc_200_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_pc_100_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_pc_50_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_pc_25_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_pc_5_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_pc_2_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp85_500_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp85_200_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp85_100_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp85_50_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp85_25_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp85_5_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp85_2_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp26_500_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp26_200_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp26_100_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp26_50_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp26_25_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp26_5_glob.tif\n",
      "[INFO] Opening: ../workspace/GIRI_raw/brazil/flood_rcp26_2_glob.tif\n",
      "[INFO] Combining arrays…\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray as rxr  # make sure: pip/conda install rioxarray\n",
    "\n",
    "folderr_brazil = \"../workspace/GIRI_raw/brazil\"\n",
    "\n",
    "# ---------------- config ----------------\n",
    "scenarios = [\"pc\", \"rcp85\", \"rcp26\"]\n",
    "return_periods = [500, 200, 100, 50, 25, 5, 2]\n",
    "\n",
    "\n",
    "out_nc  = \"../workspace/Flood/depth/ensemble_return_period.nc\"\n",
    "\n",
    "# map to human-readable names (as a coord)\n",
    "dict_scenarios = {\n",
    "    \"pc\": \"Present Climate\",\n",
    "    \"rcp85\": \"SSP5-8.5\",\n",
    "    \"rcp26\": \"SSP1-2.6\",\n",
    "}\n",
    "\n",
    "# crop extent (lon_min, lon_max, lat_max, lat_min)\n",
    "LON_MIN, LON_MAX = -75.0, -30.0\n",
    "LAT_MAX, LAT_MIN = 10.0, -35.0\n",
    "\n",
    "# chunk sizes for dask/xarray and NetCDF\n",
    "CHUNK_LAT, CHUNK_LON = 512, 512\n",
    "\n",
    "# ----------------------------------------\n",
    "list_da = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    for rp in return_periods:\n",
    "        fpath = os.path.join(folderr_brazil, f\"flood_{scenario}_{rp}_glob.tif\")\n",
    "        if not os.path.exists(fpath):\n",
    "            print(f\"[WARN] Missing: {fpath} (skipping)\")\n",
    "            continue\n",
    "\n",
    "        print(f\"[INFO] Opening: {fpath}\")\n",
    "        try:\n",
    "            da = rxr.open_rasterio(\n",
    "                fpath,\n",
    "                chunks={\"x\": CHUNK_LON, \"y\": CHUNK_LAT},\n",
    "                masked=True,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to open {fpath}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # squeeze band -> 2D (y,x)\n",
    "        if \"band\" in da.dims and da.sizes[\"band\"] == 1:\n",
    "            da = da.squeeze(\"band\", drop=True)\n",
    "\n",
    "        # ensure CRS; many global hazard tifs are EPSG:4326\n",
    "        if da.rio.crs is None:\n",
    "            da = da.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "        # crop (note: y usually descends; slice handles either order)\n",
    "        da = da.sel(x=slice(LON_MIN, LON_MAX), y=slice(LAT_MAX, LAT_MIN))\n",
    "\n",
    "        # rename dims/var\n",
    "        da = da.rename({\"x\": \"lon\", \"y\": \"lat\"})\n",
    "        da.name = \"flood_depth\"\n",
    "\n",
    "        # set dtype (float32 is compact and typical for depths)\n",
    "        da = da.astype(\"float32\")\n",
    "\n",
    "        # expand coords with scenario + return_period\n",
    "        da = da.expand_dims(\n",
    "            {\n",
    "                \"GWL\": [dict_scenarios.get(scenario, scenario)],\n",
    "                \"return_period\": [rp],\n",
    "                \"ensemble\": [\"mean\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        list_da.append(da)\n",
    "\n",
    "# guard: anything loaded?\n",
    "if not list_da:\n",
    "    raise RuntimeError(\"No rasters were found/loaded. Check file names and folder.\")\n",
    "\n",
    "# combine by coords into one cube\n",
    "print(\"[INFO] Combining arrays…\")\n",
    "da_all = xr.combine_by_coords(list_da, combine_attrs=\"override\")\n",
    "\n",
    "# order dims\n",
    "da_all = da_all.transpose(\"ensemble\",\"GWL\", \"return_period\", \"lat\", \"lon\")\n",
    "\n",
    "# set some attrs\n",
    "da_all.attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"Flood depth\",\n",
    "        \"units\": \"m\",\n",
    "        \"source\": \"UNEP GRID hazards data\",\n",
    "        \"note\": \"Cropped to South America; scenarios labelled by human-readable names.\",\n",
    "    }\n",
    ")\n",
    "da_all[\"GWL\"].attrs[\"description\"] = \"Scenario label\"\n",
    "da_all[\"return_period\"].attrs[\"units\"] = \"years\"\n",
    "\n",
    "# rechunk uniformly for writing\n",
    "da_all = da_all.chunk({\"ensemble\": 1, \"GWL\": 1, \"return_period\": 1, \"lat\": CHUNK_LAT, \"lon\": CHUNK_LON})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Writing NetCDF -> ../workspace/hazards/Flood/depth(cm)/ensemble_return_period.nc\n"
     ]
    }
   ],
   "source": [
    "# encode & save\n",
    "encoding = {\n",
    "    \"flood_depth\": {\n",
    "        \"zlib\": True,\n",
    "        \"complevel\": 4,\n",
    "        \"dtype\": \"float32\",\n",
    "        \"chunksizes\": (1, 1, 1, CHUNK_LAT, CHUNK_LON),\n",
    "        \"_FillValue\": np.float32(np.nan),  # keep NaN for no-data\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "out_nc  = \"../workspace/hazards/Flood/depth(cm)/ensemble_return_period.nc\"\n",
    "print(f\"[INFO] Writing NetCDF -> {out_nc}\")\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(out_nc), exist_ok=True)\n",
    "# da_all is already a Dataset, so just call to_netcdf directly\n",
    "da_all.to_netcdf(out_nc, encoding=encoding)\n",
    "print(\"[OK] Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
